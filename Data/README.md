# Data Engineering Portfolio

Welcome to my Data Engineering Portfolio! Here, you will find a curated collection of projects that showcase my skills and experience in data engineering. Each project has been carefully selected to demonstrate my ability to clean, organize, and analyze data, as well as build efficient data pipelines. Whether you're a potential employer, a fellow data enthusiast, or just curious about my work, I hope you find these projects informative and inspiring. Feel free to explore and reach out if you have any questions or comments. Enjoy your visit!

## About Me

Hello! My name is João Paulo, and I hold a degree in Biological Sciences. Currently, I am embarking on an exciting career transition into the tech world, with a particular focus on data, encompassing both data engineering and data science. Although I am relatively new to this field, I am deeply committed to continuously developing my skills and seeking experiences that expand my knowledge and competence in these areas.

My journey into data started recently, but it is already filled with intense learning and practical application. I am currently enhancing my skills through specialized courses on Codecademy, where I am learning Python and Data Engineering (in fact, most of this portfolio pertains to projects I developed while finishing their courses!). These courses are providing me with a solid foundation in programming, data analysis, large dataset manipulation, and the use of relevant frameworks and libraries, such as Pandas and Matplotlib. These skills are fundamental for anyone aspiring to excellence in data science and engineering.

Moreover, I have dedicated myself to practical projects that not only allow me to apply what I have learned but also to face real challenges that simulate the work environment I will encounter in the future. Among these projects, I highlight the development of a notification system in Ruby on Rails, a Flask application for cost calculation based on XML data, and other projects in various fields that you can find on my [Github profile](https://github.com/jampamatos).

My previous experience as an intern at Embrapa, where I was responsible for collecting, processing, and analyzing data for research projects, significantly contributed to my interest and skills in data. Additionally, my time as a teaching assistant at Colégio Apogeu and as a financial manager at a paint store taught me about responsibility, management, and the importance of precise and well-analyzed data for effective decision-making.

I am eager for opportunities that allow me to apply my knowledge in data science and engineering, face new challenges, and contribute to projects that not only use data to solve problems but also create value in an ethical and sustainable manner. I know I am at the beginning of my career in data, but I am equipped with the passion, dedication, and willingness to learn and grow in this field.

Thank you for the opportunity to share my profile, and I am excited about the possibility of contributing to your team, bringing new ideas and data-driven approaches to tackle the challenges of the modern world. I look forward to exploring opportunities to collaborate, learn, and evolve in the field of data.

You can find me on [Linkedin](https://www.linkedin.com/in/jampamatos/), and also on [Twitter](https://x.com/jumpamatos).

## Portfolio Overview

This portfolio showcases a collection of data engineering projects that I have developed to demonstrate my skills and knowledge in the field. Each project has been meticulously curated to highlight my ability to handle various data engineering tasks, including data cleaning, organization, analysis, and building efficient data pipelines.

In this portfolio, you will find projects that utilize different tools and technologies, such as Python, Pandas, Matplotlib, PySpark, SQL, and Bash scripting. These projects represent real-world scenarios and challenges that I have tackled, providing a comprehensive view of my practical experience and problem-solving capabilities.

The primary goals of this portfolio are to:
- Illustrate my proficiency in data engineering techniques and methodologies.
- Showcase my ability to work with large datasets and perform complex data manipulations.
- Highlight my experience with various data tools and frameworks.
- Demonstrate my commitment to producing high-quality, reproducible, and well-documented work.

Feel free to explore each project in detail. I have included a brief description, the main skills demonstrated, and a link to the project repository for your convenience. If you have any questions or would like to discuss any of the projects further, please do not hesitate to [reach out](mailto:jp.coutm@gmail.com).

Thank you for taking the time to review my portfolio. I hope you find these projects as insightful and exciting as I found them to create.

## Projects

In this section, you will find detailed descriptions of the data engineering projects I have completed. Each project has been designed to address specific challenges and demonstrate my expertise in various aspects of data engineering. The projects are organized to provide you with an overview of the objectives, the technologies and tools used, and the key skills and methodologies applied.

For each project, you will find:
- A brief description of the project's goals and context.
- The primary skills and techniques demonstrated.
- A link to the full project repository for further exploration.

These projects showcase my ability to clean, process, and analyze data, as well as to build and automate efficient data pipelines. I invite you to explore each project to see the depth and breadth of my experience in data engineering.

### Bike Rental

**Description:** This was my first Data Engineering project, where I worked with CSV data from a bike rental company and weather data spanning an entire year. The project involved cleaning and organizing the datasets, and then conducting analyses to explore the relationship between temperature and bike rentals. This project was developed in a Jupyter Notebook.

**Skills Demonstrated:**
- Data cleaning and preprocessing
- Data integration from multiple sources
- Exploratory data analysis
- Visualization of data trends using Jupyter Notebook

**Project Repository:** [Bike Rental Project](https://github.com/jampamatos/codecademy_stuff/blob/main/Data/bike_rental/Bike%20Rental%20Project.ipynb)

### Stack Overflow Survey

**Description:** This project involved analyzing data from a Stack Overflow survey. It was my first project using Pandas and Matplotlib, where I focused on extracting insights from the survey data. The analysis was conducted in a Python script, demonstrating my ability to handle and visualize large datasets.

**Skills Demonstrated:**
- Data analysis using Pandas
- Data visualization with Matplotlib
- Extracting insights from survey data
- Scripting in Python for data processing

**Project Repository:** [Stack Overflow Survey Project](https://github.com/jampamatos/codecademy_stuff/blob/main/Data/stack-overflow-survey/main.py)

### Subscriber Pipeline

**Description:** This project marks my first complete and automated data pipeline. I worked on provided data, cleaning and organizing it before creating Python and Bash scripts to generate changelogs of changes and update databases. The project demonstrates my ability to automate data workflows and manage data transformation processes. This project was developed in a Jupyter Notebook.

**Skills Demonstrated:**
- Data cleaning and organization
- Automation of data workflows using Python and Bash
- Creation of changelogs for data updates
- Database management and updates

**Project Repository:** [Subscriber Pipeline Project](https://github.com/jampamatos/codecademy_stuff/blob/main/Data/subscriber-pipeline/Subscriber%20Pipeline.ipynb)

### Analyzing Wikipedia Clickstream Data

**Description:** This project was my first experience using PySpark. I used samples of Wikipedia clickstream data to create data frames in Pandas and SQL databases for analysis and queries. The project involved handling large datasets and performing complex data manipulations to extract meaningful insights. This project was developed in a Jupyter Notebook.

**Skills Demonstrated:**
- Data manipulation with PySpark
- Creation and management of data frames
- SQL database creation and querying
- Handling large datasets for analysis

**Project Repository:** [Analyzing Wikipedia Clickstream Data Project](https://github.com/jampamatos/codecademy_stuff/blob/main/Data/wikipedia_clickstreams/notebook.ipynb)

## Tools and Technologies

Throughout these projects, I have used various tools and technologies, including:

- **Programming Languages:** Python, Bash, SQL
- **Libraries and Frameworks:** Pandas, Matplotlib, PySpark
- **Tools:** Jupyter Notebook, Git, GitHub, PostgreSQL

## Contact

If you have any questions or would like to discuss any of my projects further, please feel free to reach out:

- Email: [jp.coutm@gmail.com](mailto:jp.coutm@gmail.com)
- Linkedin: [João Paulo Coutinho de Matos](https://www.linkedin.com/in/jampamatos/) 
- Twitter: [@jumpamatos](https://x.com/jumpamatos).